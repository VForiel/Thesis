\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Custom packages
\usepackage{color,soul} % For highlighting text
\usepackage{float} % For controlling figure placement ([H] option)
\usepackage{amsmath}
\usepackage{amssymb} % For mathematical symbols such as \lessgtr
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\definecolor{mulberry}{rgb}{0.77, 0.29, 0.55}
\newcommand{\dm}[1]{{\color{mulberry} #1}}

\newcommand{\mi}{\mathrm{i}}

\title{Analyse statistique des distributions de sortie du Kernel-Nulling pour la détection à haut contraste d'exoplanètes dans les configurations VLTI et LIFE}

\author{Vincent Foriel,
        David Mary,
        Frantz Martinache
       }

\begin{document}

\maketitle

\begin{abstract}
L'interférométrie à annulation par noyau (Kernel-Nulling) \cite{Martinache2018} représente une approche prometteuse pour la détection directe d'exoplanètes. Cette technique génère des distributions d'intensité caractéristiques selon la présence ou l'absence d'un compagnon planétaire. L'analyse statistique de ces distributions est essentielle pour une détection robuste de planètes \cite{Hanot2011}. Nous développons et comparons plusieurs tests statistiques pour discriminer efficacement entre les hypothèses $\mathcal{H}_0$ (étoile seule) et $\mathcal{H}_1$ (système étoile-planète). Nous analysons les performances de différentes statistiques de test afin d'évaluer la pertinence de chacun d'eux en fonction de la nature des données à disposition. Nous effectuons des simulations numériques pour trois scenarios instrumentaux : les configurations VLTI au sol \cite{Chingaipe2023} et celle de LIFE dans l'espace ainsi qu'un scénario fictif consistant à placer le VLTI dans l'espace afin d'isoler les pertes de performance causées par l'atmosphère. Pour chaque scénario, nous générons des jeux de données sous les deux hypothèses $\mathcal{H}_0$ et $\mathcal{H}_1$, en tenant compte des paramètres instrumentaux spécifiques et des niveaux de bruit. Nous évaluons les performances des tests en utilisant les courbes ROC et l'analyse des valeurs P. Cette analyse statistique, actuellement appliquée à des données simulées, ouvre la voie à une détection robuste d'exoplanètes à haut contraste utilisant l'interférométrie à annulation par noyau.
\end{abstract}

\subsection{Tests statistiques}

En présence d'un compagnon (hypothèse $\mathcal{H}_1$), la distribution de sortie du Kernel-Nulling est modifiée par rapport au cas de l'étoile seule (hypothèse $\mathcal{H}_0$) comme le montre la figure \ref{fig:distribution}.

Cette modification se manifeste principalement par un décalage de la distribution, bien que d'autres changements dans la forme de la distribution puissent également survenir. En fonction des conditions, il est par exemple possible de constater un applatissement de la distribution. Pour détecter efficacement la présence d'un compagnon, nous avons implémenté et évalué plusieurs tests statistiques, chacun étant sensible à différents aspects des distributions.

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{img/output_distribution.png}
\caption{Example of kernel nulling depth distributions for hypotheses $\mathcal{H}_0$ (star alone) and $\mathcal{H}_1$ (with companion). This example scenario is heavily exaggerated with a companion having low contrast to induce a significant distribution shift. In practice, the two distributions are generally much closer and difficult to distinguish.\dm{Cf texte; aussi prends l'habitude d'être ultra-spécifique, c'est un papier scientifique. Là tu es bcp trop vague : "low contrast" (c'est quoi low ?) "much closer" (=?..)}.}
\label{fig:distribution}
\end{figure}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\subsubsection{Likelihood Ratio (LR) et approche paramétrique}
Le test du rapport de vraisemblance (LR) consiste à comparer la probabilité d'observer les données sous chaque hypothèse :
\begin{equation}
    \Lambda(x) = \frac{p(x;\mathcal{H}_1)}{p(x;\mathcal{H}_0)}
\end{equation}
Ce test est optimal au sens de Neyman-Pearson. Cependant, il nécessite une connaissance analytique des distributions, qui est ici inconnue.
Une première approche pour approximer ce test consiste à ajuster des modèles paramétriques (Cauchy, Laplace) sur les distributions simulées, comme discuté précédemment. Cela permet de construire un test de rapport de vraisemblance basé sur ces lois ajustées.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\subsubsection{Generalized Likelihood Ratio (GLR)}

Une alternative puissante, qui ne nécessite pas de connaître la forme analytique exacte de la distribution des sorties du nuller mais qui exploite la connaissance du modèle instrumental direct, est le rapport de vraisemblance généralisé (GLR).

Le principe est d'utiliser le modèle direct de l'instrument pour prédire le signal attendu pour une position et un contraste de planète donnés, et de comparer les résidus observés sous les deux hypothèses.
Si l'on suppose que le bruit (après soustraction du modèle) suit une loi connue (par exemple gaussienne ou approximativement gaussienne en raison du théorème central limite sur un grand nombre de données, ou une loi à queues lourdes modélisée empiriquement), on peut écrire la vraisemblance.

Sous $\mathcal{H}_0$ (pas de planète), le signal attendu est nul (ou égal au fond résiduel). Sous $\mathcal{H}_1$, le signal dépend des paramètres de la planète $\theta$ (position, contraste). Le GLR consiste à maximiser la vraisemblance sous $\mathcal{H}_1$ par rapport à ces paramètres inconnus :

\begin{equation}
    \Lambda_{GLR}(x) = \frac{\sup_{\theta} p(x | \theta, \mathcal{H}_1)}{p(x | \mathcal{H}_0)}
\end{equation}

En supposant un bruit indépendant sur chaque mesure $x_i$, le log-GLR devient :
\begin{equation}
    \log \Lambda_{GLR}(x) = \sup_{\theta} \sum_i \left( \log p(x_i | \theta, \mathcal{H}_1) - \log p(x_i | \mathcal{H}_0) \right)
\end{equation}

Cette méthode est particulièrement intéressante car elle permet non seulement la détection mais aussi l'estimation des paramètres de la planète (la valeur de $\theta$ qui maximise la vraisemblance). Elle est cependant plus coûteuse en calcul car elle nécessite une optimisation sur la grille des paramètres.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsubsection{Moyenne}

Le test le plus naturel a faire dans ces conditions consiste à comparer la moyenne à un seuil. Etant donné que la planète peut induire un décallage de la distribution dans les deux sens, on utilise la valeur absolue de la moyenne.

$$
D_{M} = \left|\frac{1}{N}\sum_{i=1}^N x_i \right| \stackrel{H_1}{\underset{H_0}{\gtrless}} \xi
$$

En pratique, on constate que la moyenne est ici une statistique de test particulièrement peu fiable (figure \ref{fig:roc}) en raison de sa sensibilité aux valeurs extrêmes des distributions à queues lourdes.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsubsection{Médiane}
La médiane, définie comme la valeur centrale d'un ensemble de données triées, est intrinsèquement plus robuste aux valeurs extrêmes.
$$
D_m = \text{median}(|x|) \stackrel{H_1}{\underset{H_0}{\gtrless}} \xi
$$
Surprenament, la médiane s'avère être une statistique de test très performante dans ce contexte (figure \ref{fig:roc}), surpassant bon nombre de tests plus sophistiqués. Elle capture efficacement le décalage global de la distribution tout en ignorant les queues lourdes non-informatives ou bruitées.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsubsection{Kolmogorov-Smirnov}

Le test de Kolmogorov-Smirnov (KS) compare les fonctions de distribution cumulative (CDF) empiriques.
$$
D_{KS} = \sup_x |F_{obs}(x) - F_{ref}(x)| \stackrel{H_1}{\underset{H_0}{\gtrless}} \xi
$$
Le test KS est sensible à toute déformation de la distribution (décalage, aplatissement, changement de forme). Il s'avère robuste et efficace, mais nécessite un échantillon de référence fiable pour $\mathcal{H}_0$.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsubsection{Flattening}

Nous avons défini une statistique "flattening" mesurant la dispersion absolue autour de la médiane :
$$
D_f = \frac 1 N \sum_{i=1}^N |x_i - \tilde{x}| \stackrel{H_1}{\underset{H_0}{\gtrless}} \xi
$$
Ce test vise à détecter l'aplatissement de la distribution induit par le compagnon. Bien que moins performant seul, il confirme que la modification de la forme de la distribution est une information exploitable.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsubsection{Median of Absolute Values (MAV)}

Cette statistique combine la robustesse de la médiane et la sensibilité au décalage et à l'étalement :
$$
D_{MAV} = \text{median}(|x_i|) \stackrel{H_1}{\underset{H_0}{\gtrless}} \xi
$$
C'est l'une des statistiques les plus performantes sur nos simulations, bénéficiant à la fois du décalage de la moyenne (via les valeurs absolues) et de la robustesse de la médiane.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsubsection{Autres tests considérés}\label{sec:other_tests}
Nous avons également exploré d'autres tests (Cramer-von Mises, Wilcoxon-Mann-Whitney, Anderson-Darling, Brunner-Munzel) qui n'ont pas montré de gain significatif par rapport aux méthodes plus simples présentées ci-dessus.

%==============================================================================
\section{Généralisation}
%==============================================================================

Jusqu'à présent, nous avons considéré l'analyse d'une seule sortie de Kernel-Nulling (un seul noyau) pour une seule configuration instrumentale. Cependant, les instruments réels comme le VLTI ou LIFE produisent plusieurs sorties Kernel simultanées (K1, K2, K3, etc.) \cite{Laugier2020} et l'observation se fait souvent sur plusieurs poses (rotation de la ligne de base) pour couvrir le plan (u,v).

La généralisation des tests statistiques à ces cas multidimensionnels est cruciale.

\subsection{Combinaison de plusieurs Kernels}
Les différentes sorties Kernel sont généralement corrélées car elles proviennent des mêmes entrées photométriques perturbées. Cependant, dans une première approximation ou si l'on utilise des décorrélateurs (comme la matrice de covariance du bruit), on peut combiner les statistiques.
Pour le GLR, la généralisation est naturelle : la vraisemblance totale est la somme des log-vraisemblances de chaque sortie (en tenant compte de la matrice de covariance $\Sigma$ si nécessaire) :

\begin{equation}
    \log \Lambda_{tot} = \sum_{k} \log \Lambda_k(x^{(k)})
\end{equation}
Pour des statistiques comme la médiane ou la MAV, une approche consiste à calculer la statistique sur chaque Kernel individuellement, puis à combiner ces valeurs (par exemple, somme des carrés ou somme pondérée) pour former une statistique globale.

\subsection{Combinaison de plusieurs Poses}
Les observations à différents angles de rotation sont temporellement décorrélées (si le temps entre poses est supérieur au temps de cohérence atmosphérique). L'information planétaire varie d'une pose à l'autre (modulation du signal).
Le GLR exploite parfaitement cette modulation : le modèle direct $p(x | \theta, \mathcal{H}_1)$ prédit exactement cette variation en fonction de la position $\theta$ testée. C'est ici que le GLR prend tout son sens par rapport aux tests scalaires simples (comme la médiane globale) qui pourraient "moyennner" le signal planétaire variable.

%--------------------------------------------------------------------

\section{Résultats}

\subsection{Courbes ROC}

Les courbes ROC (Receiver Operating Characteristic) permettent de comparer l'efficacité de différentes statistiques de test.

\begin{figure}[H]
\centering
\includegraphics[width=7cm]{img/roc_curves.png}
\caption{Courbes ROC pour différentes statistiques de test sur les distribution simulées dans le contexte du VLTI avec un compagnon de contraste $10^{-2}$.}
\label{fig:roc}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=7cm]{img/neyman_pearson.png}
\caption{Courbes ROC pour différentes statistiques de test comparées au test optimal de Neyman-Pearson, dans le contexte du VLTI avec un compagnon de contraste $10^{-3}$.}
\label{fig:neyman-pearson}
\end{figure}

\subsection{Analyse des valeurs P}

Les valeurs P fournissent une mesure de la probabilité d'obtenir une statistique de test au moins aussi extrême que celle observée, sous l'hypothèse nulle.

\begin{figure}[H]
\centering
\includegraphics[width=10cm]{img/p-values.png}
\caption{Évolution des valeurs P en fonction du seuil pour différentes statistiques de test.}
\label{fig:pvalues}
\end{figure}

%--------------------------------------------------------------------

\section{Discussion}

\subsection{Performance comparative des tests}
Nos résultats montrent une hiérarchie claire dans les performances des tests :
\begin{enumerate}
    \item \textbf{GLR et MAV} : Offrent les meilleures performances. Le GLR est optimal car il utilise toute l'information du modèle, tandis que la MAV est une approximation robuste très efficace.
    \item \textbf{Médiane et KS} : Très performants et robustes, mais nécessitent plus de données pour converger.
    \item \textbf{Moyenne} : Peu performante en raison de la sensibilité aux queues de distribution.
\end{enumerate}

\subsection{Sensibilité au bruit}
La robustesse des tests basés sur la médiane (Médiane, MAV) face aux valeurs aberrantes (queues lourdes) est un atout majeur dans le régime de fort bruit atmosphérique (VLTI). Pour LIFE (bruit instrumental dominé, plus stable), les écarts entre moyenne et médiane tendent à se réduire, mais la médiane reste une valeur sûre.

%-----------------------------------------------------------------

\section{Conclusion}

Dans cette étude, nous avons analysé les propriétés statistiques des sorties de Kernel-Nulling et évalué plusieurs méthodes de détection.

\textbf{Bilan des méthodes :}

\begin{itemize}
    \item \textbf{Moyenne} :
    \begin{itemize}
        \item[+] Simple à calculer.
        \item[-] Très sensible aux valeurs aberrantes, peu fiable pour les distributions à queues lourdes.
    \end{itemize}
    
    \item \textbf{Médiane / MAV} :
    \begin{itemize}
        \item[+] Très robuste, excellentes performances empiriques.
        \item[-] Nécessite un tri des données (coût $O(N \log N)$), demande un nombre d'échantillons suffisant.
    \end{itemize}
    
    \item \textbf{Kolmogorov-Smirnov} :
    \begin{itemize}
        \item[+] Non-paramétrique, capture toutes les déformations.
        \item[-] Moins puissant que les tests ciblés (GLR) pour un signal spécifique.
    \end{itemize}
    
    \item \textbf{GLR (Generalized Likelihood Ratio)} :
    \begin{itemize}
        \item[+] Approche théoriquement optimale, permet l'estimation des paramètres, gère naturellement la fusion de données (multi-kernel, multi-pose).
        \item[-] Coût de calcul élevé (optimisation), nécessite un modèle direct précis.
    \end{itemize}
\end{itemize}

En conclusion, pour une détection rapide et robuste, la \textbf{Médiane des Valeurs Absolues (MAV)} est recommandée comme "first look". Pour une analyse approfondie et l'estimation des paramètres de l'exoplanète, le \textbf{GLR} constitue la méthode de référence, permettant de combiner rigoureusement toutes les informations disponibles.

\bibliographystyle{alpha}
\bibliography{sample}

\end{document}